```ts
// createUploadManager.ts
import SparkMD5 from 'spark-md5';
import upload from './request';

const isDev = __DEVELOPMENT__;

function fetch({url, method = 'GET', data}) {
  if (method === 'GET' && data) {
    url += `?${new URLSearchParams(data).toString()}`;
  }
  return new Promise((resolve, reject) => {
    const request = new XMLHttpRequest();
    request.open(method, url, true);

    request.onload = event => {
      // 需要处理返回的 response text => json
      // 解析失败 & status != 200 都需要考虑为 error
      if (request.status < 200 || request.status >= 300) {
        reject({request, event});
        return;
      }

      try {
        const response = JSON.parse(request.responseText);
        resolve(response || {});
      } catch (err) {
        reject({request, event, err});
      }
    };

    request.addEventListener('error', event => {
      reject({request, event});
    });

    request.send(method === 'GET' ? null : JSON.stringify(data || {}));
  });
}

const getHashes = data => fetch({url: '/common/check/file.json', data}).then(res => {
  if (['OK', 'ok'].includes(res?.status)) {
    return res.data || [];
  }
  return [];
});
const onMerge = data => fetch({method: 'POST', url: '/common/attachment/file/merge.json', data});

const BRAAND_WIDTH = navigator.connection?.downlink || 5; // 5M/s

class SplitChunkHash {
  file = null;
  chunks = [];
  chunk_per_size = [];
  chunkSize = 1024 ** 2 * 5; // 5MB

  constructor(file, chunkSize) {
    if (chunkSize) {
      this.chunkSize = chunkSize;
    }
    this.file = file;
    const THREAD_COUNT = navigator.hardwareConcurrency || 4;
    this.chunkCount = Math.ceil(file.size / this.chunkSize);
    this.threadChunkCount = Math.ceil(this.chunkCount / THREAD_COUNT);
    this.group = Math.min(this.chunkCount, THREAD_COUNT);
  }

  ready() {
    let total = 0;
    const group = this.group;
    return new Promise(resolve => {
      const onMessage = (worker, start, end) => e => {
        for (let i = start; i < end; i++) {
          this.chunks[i] = e.data[i - start];
        }
        worker.terminate();
        total++;
        if (total === group) {
          console.log(this.chunks);
          resolve(this.chunks);
        }
      };
      // 启用多线程同时解析文件 hash，每个线程处理 {chunkCount}/{group} 个文件块
      for (let i = 0; i < group; i++) {
        const worker = new Worker(new URL('./worker.js', import.meta.url), {
          type: 'module',
        });
        let end = (i + 1) * this.threadChunkCount;
        if (end > this.chunkCount) {
          end = this.chunkCount;
        }
        const start = i * this.threadChunkCount;
        worker.postMessage({
          file: this.file,
          size: this.chunkSize,
          startIndex: start,
          endIndex: end,
        });
        worker.onmessage = onMessage(worker, start, end);
      }
    });
  }
  get hash() { // 文件 hash 根据各个分块 hash 生成，不再耗费时间对整体文件 hash
    const spark = new SparkMD5();
    this.hashes.forEach(hash => spark.append(hash));
    return spark.end();
  }
  get hashes() {
    return this.chunks.map(({ hash }) => hash);
  }
  async filter(fetch) {
    this.chunk_per_size = this.chunks.map(({ size }) => size);
    // 通过接口获取已经上传的分块 hash，保留尚未上传的
    const hashes = await fetch(this.hash);
    let chunks_need_upload = this.chunks;
    if (Array.isArray(hashes)) {
      chunks_need_upload = this.chunks.filter((item, index) => {
        if (!hashes.includes(item.hash)) {
          this.chunk_per_size[index] = 0;
          return true;
        }
        return false;
      });
    }
    return chunks_need_upload;
  }
  get uploadedSize() {
    return this.chunk_per_size.reduce((total, size) => total + size, 0);
  }
  onProgress(e, {index}) {
    // 计算上传整体进度
    this.chunk_per_size[index] = e.loaded;
    const size = this.file.size;
    // 未完成前，进度条不能超过 100%
    const percentage = Math.min(100 * this.uploadedSize / size, 99.9);
    return +percentage.toFixed(2);
  }
  get predictRestTime() {
    const restSizeB = this.file.size - this.uploadedSize;
    const realRestTime =  Math.max(restSizeB / (1024 ** 2) / BRAAND_WIDTH, 1);
    // 未完成前，剩余时间小于 1s 时按 1s 返回
    return +realRestTime.toFixed(1);
  }
}

export default class UploadManager {
  constructor({
    parallel = 6,
    ...option
  }) {
    this.parallel = parallel;
    this.option = option;
    this.uploadingFiles = [/*
    {
      file: File,
      percentage: number,
      restTime: number,
      index: number,
    }
    */];
    this.onChange = this.onChange.bind(this);
  }
  // @return Promise<FileObject>
  onMerge(body) {
    isDev && console.warn(`
      Please register onMerge function for blob chunk merging.
      Or the blob chunks won't be merged.
    `);
    const data = {
      ...this.option.data,
      ...body,
    };
    return onMerge(data);
  }
  onProgress({ id, file, percentage, restTimeSec }) {
    console.info(`Upload ${file.name} percentage: `, percentage, '%, ', 'rest time: ', restTimeSec, 's');
    if (percentage === 100) {
      this.uploadingFiles = this.uploadingFiles.filter(item => item.id !== id);
      return;
    }
  }
  // 定义上传成功的响应解析器，若表示失败，务必返回 Promise.reject();
  // @param {Response} res
  // @return {Promise<unknow>}
  resonseParser(response) {
    return response;
  }
  // 定义合并文件的回调，合并后的文件作为参数
  // @param {Response}
  onAppendFile(file) {
    console.error('Merged file: ', file, 'Please register onAppendFile method.');
  }
  /*
    @param string md5 文件哈希
    @return Hash[] | Promise<Hash[]> // 返回已上传过的文件哈希
  */
  getUploadedFileHashes(fileMd5) {
    isDev && console.warn(`
      File hash: ${fileMd5} is ready.
      Please register getUploadedFileHashes for blob chunk uploaded check.
      Or you may get a lot of duplicated uploaded chunks.
    `);
    return getHashes({fileMd5});
  }

  register(funcMap = {}) {
    Object.entries(funcMap).forEach(([key, func]) => {
      if (
        ['onMerge', 'onAppendFile', 'getUploadedFileHashes', 'resonseParser'].includes(key)
        && typeof func === 'function'
      ) {
        this[key] = func;
      }
    });
    return this;
  }

  updateCurFile(id, percentage, restTimeSec) {
    const curFile = this.uploadingFiles.find(item => item.id === id);
    if (!curFile) return;
    Object.assign(curFile, {
      percentage,
      restTimeSec,
    });
    this.onProgress(curFile);
  }

  async onChange(e, chunkSize) {
    const files = e.target.files;
    const length = files.length;
    for (let i = 0; i < length; i++) {
      const file = files[i];
      const splitHash = new SplitChunkHash(file, chunkSize);
      await splitHash.ready();
      const uploadChunks = await splitHash.filter(this.getUploadedFileHashes);
      const md5 = splitHash.hash; // 文件 hash
      const curFile = { file, percentage: 0.01, restTimeSec: '-', id: md5 };
      this.uploadingFiles.push(curFile);
      // console.log('文件 md5：', md5);
      const updateCurFile = this.updateCurFile.bind(this);
      const merge = () => this.onMerge({
        hashes: splitHash.hashes,
        md5,
        fileName: file.name,
      }).then(mergeFile => { // 直到合并后再触发 100%
        updateCurFile(md5, 100, 0);
        this.onAppendFile(mergeFile, file);
      });
      if (!uploadChunks.length) {
        console.info('文件已存在，跳过上传，直接合并');
        updateCurFile(md5, 99, 1);
        merge();
        continue;
      }
      const promises = uploadChunks.map(({ file: blob, ...data }) =>
        () => upload({
          ...this.option,
          /* filename, action, headers, onProgress, */
          file: blob,
          onProgress(e) {
            const loadPercentage = splitHash.onProgress(e, data);
            updateCurFile(md5, loadPercentage, splitHash.predictRestTime);
          },
          data: Object.assign({ md5 }, data),
        }).then(this.resonseParser)
      );
      upload.parallel(promises, this.parallel)
        .then(merge) // 调用文件合并接口
        .catch(err => {
          console.error(err);
        });
    }
  }
}
```

```ts
// request.js
function sendRequest(option) {
  function getError(action, xhr) {
    let msg = '';
    if (xhr.response) {
      msg = xhr.status + ' ' + (xhr.response.error || xhr.response);
    } else if (xhr.responseText) {
      msg = xhr.status + ' ' + xhr.responseText;
    } else {
      msg = 'fail to post ' + action + ' ' + xhr.status;
    }

    const err = new Error(msg);
    err.status = xhr.status;
    err.method = 'post';
    err.url = action;
    return err;
  }

  function getBody(xhr) {
    const text = xhr.responseText || xhr.response;
    if (!text) {
      return text;
    }

    try {
      return JSON.parse(text);
    } catch (e) {
      return text;
    }
  }

  function upload(option) {
    if (typeof XMLHttpRequest === 'undefined') {
      return;
    }

    const xhr = new XMLHttpRequest();
    const action = option.action;

    if (xhr.upload) {
      xhr.upload.onprogress = function progress(e) {
        if (e.total > 0) {
          e.percent = e.loaded / e.total * 100;
        }
        option.onProgress(e);
      };
    }

    const formData = new FormData();

    if (option.data) {
      Object.keys(option.data).forEach(key => {
        formData.append(key, option.data[key]);
      });
    }

    formData.append(option.filename, option.file, option.file.name);

    xhr.onerror = function error(e) {
      option.onError(e);
    };

    xhr.onload = function onload() {
      if (xhr.status < 200 || xhr.status >= 300) {
        return option.onError(getError(action, xhr));
      }

      return option.onSuccess(getBody(xhr));
    };

    xhr.open('post', action, true);

    if (option.withCredentials && 'withCredentials' in xhr) {
      xhr.withCredentials = true;
    }

    const headers = option.headers || {};

    Object.entries(headers).forEach(([key, value]) => {
      if (value !== null) {
        xhr.setRequestHeader(key, value);
      }
    });
    xhr.send(formData);
  }

  upload(option);
}

function reqParallelController(promises, parallel = 6) {
  const errors = [];
  const result = [];
  const total = promises.length;
  return new Promise((resolve, reject) => {
    const stack = promises.slice(0, parallel);
    const rest = promises.slice(parallel);

    const onNext = () => {
      if (rest.length) {
      // eslint-disable-next-line no-use-before-define
        start(rest.shift());
      } else if (result.length + errors.length === total) { // allSettled
        // if error exists, reject with all errors, otherwise resolve with all results
        errors.length ? reject(errors) : resolve(result);
      }
    };
    const start = promise => promise().then(res => {
      result.push(res);
    }).catch(e => errors.push(e)) // 某些分片上传失败不中断整体上传，所以这里不 reject
      .finally(onNext);

    stack.forEach(start);
  });
}

function request(option) {
  return new Promise((resolve, reject) => {
    sendRequest({
      filename: 'file',
      ...option,
      onSuccess: resolve,
      onError: reject,
      onProgress(e) {
        typeof option.onProgress === 'function' ? option.onProgress(e) : console.info(e.percent + '%');
      },
    });
  });
}

request.parallel = reqParallelController;

export default request;
```

```ts
// worker.js
import SparkMD5 from 'spark-md5';

const slice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;

function createChunk(file, i, size) {
  return new Promise(resolve => {
    const reader = new FileReader();
    const start = i * size;
    const end = start + size;
    const spark = new SparkMD5.ArrayBuffer();
    const blob = slice.call(file, start, end);
    reader.onload = e => {
      spark.append(e.target.result);
      resolve({
        start,
        end,
        index: i,
        hash: spark.end(),
        file: blob,
        size: blob.size,
      });
    };
    reader.readAsArrayBuffer(blob);
  });
}

onmessage = async e => {
  const {
    file,
    size,
    startIndex,
    endIndex,
  } = e.data;
  const promises = [];
  for (let i = startIndex; i < endIndex; i++) {
    promises.push(createChunk(file, i, size));
  }
  const chunks = await Promise.all(promises);
  postMessage(chunks);
};
```